Logestic regression = {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'} acc= 81.43%
Decision tree = {'criterion': 'entropy', 'max_depth': 1300} acc = 77.44%
MLP = {'activation': 'tanh', 'alpha': 0.0001, 'learning_rate': 'adaptive', 'solver': 'adam'} acc = 82.92%
KNN = {'n_neighbors': 13, 'weights': 'distance'} acc = 83.84%
SVM = {'C': 1, 'kernel': 'rbf', gamma: 'scale'} acc = 79.8%
RF = {'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 3, 'n_estimators': 1300} acc = 84.64%