{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_style('dark')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Read Data and discover its info</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "data = pd.read_csv('data/weatherAUS.csv')\n",
    "\n",
    "# Show first 5 Rows from data.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data dimensions.\n",
    "# We have 145460 records with 22 independent variables and one dependent variable (RainTomorrow).\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if data attributes have any NA values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the previous cell we can see that we have alot of NA values in dataset.\n",
    "# And we have NA values in the dependent variable itself, so we need to remove this records from data.\n",
    "data = data[data['RainTomorrow'].notna()]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check percenatage of NA values in data attributes.\n",
    "data.isnull().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous cell we can see that Evaporation, Sunshine, Cloud9am and Cloud3pm\n",
    "# have almost 50% of thier record missing which can have negative effect on our model.\n",
    "data.drop(['Evaporation','Sunshine','Cloud9am','Cloud3pm'],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = data.select_dtypes(include=[\"float64\",\"int64\"]).columns     # Numerical data attributes --> 12 Features\n",
    "categoricalCols = data.select_dtypes(include=\"object\").columns  # Categorical daata attributes --> 7 Features\n",
    "\n",
    "# We can notice that we have Categorical data less than numerical.\n",
    "print(numericCols)\n",
    "print(categoricalCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique values in each categorical attribute to see if we can convert them into numerical.\n",
    "# Only Date and Location attribute has many different values 3436 and 49 respectivly.\n",
    "# But we can ignore Location column because it's implicitly defined by the other whether features, and doesn't give new info.\n",
    "# The same is for Date each date entry is given by day-month-year which is implicitly defined by the other whether features.\n",
    "for col in categoricalCols:\n",
    "    print(f\"{col}: {data[col].nunique()}\")\n",
    "\n",
    "# Remove flight column\n",
    "data.drop(['Date','Location'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualize Data and Correlations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See counts of each class for RainTomorrow in dataset.\n",
    "plt.figure()\n",
    "plt.subplot()\n",
    "plt.title(\"Classes Count\")\n",
    "sns.countplot(x='RainTomorrow',data=data)\n",
    "plt.show()\n",
    "# We can see that data is unbalanced so maybe we need to do resampling.\n",
    "\n",
    "# See counts of each class for RainToday in dataset.\n",
    "plt.figure()\n",
    "plt.subplot()\n",
    "plt.title(\"Classes Count\")\n",
    "sns.countplot(x='RainToday',data=data)\n",
    "plt.show()\n",
    "# We can notice that RainTomorrow and RainToday has the same histogram, so maybe they affect each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Raintomorrow and RainToday attributes into numericals.\n",
    "data['RainTomorrow'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "data['RainToday'].replace(['No', 'Yes'],[0, 1], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets analyze how temp. affect the probability of raining tomorrow.\n",
    "# We have in our data 4 sources for temp (MaxTemp, MinTemp, Temp9am, Temp3pm)\n",
    "# Lets how these values affect our target.\n",
    "sns.heatmap(data[['MinTemp','MaxTemp','Temp3pm','Temp9am', 'RainTomorrow']].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After seeing the correlation matrix we can notice that these variables are not affect our target variable too much.\n",
    "# But we can extract useful information from it by taking difference between the temps. \n",
    "data['DiffMinMaxTemp'] = data['MaxTemp'] - data['MinTemp']\n",
    "data['DiffTemp'] = data['Temp3pm'] - data['Temp9am']\n",
    "data[['DiffMinMaxTemp','MinTemp','MaxTemp','DiffTemp','Temp3pm','Temp9am', 'RainTomorrow']].corr()\n",
    "sns.heatmap(data[['DiffMinMaxTemp','MinTemp','MaxTemp','DiffTemp','Temp3pm','Temp9am', 'RainTomorrow']].corr(), annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can see that we converted the unuseful variable to be more useful and more correlated to our target.\n",
    "# Lets drop old variables\n",
    "data.drop(['MinTemp','MaxTemp','Temp3pm','Temp9am'],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets analyze how the pressure affect the probability of raining tomorrow.\n",
    "# We have in our data 2 sources for temp (Pressure3pm, Pressure9am)\n",
    "# Lets show how these values affect our target.\n",
    "data['DiffPressure'] = data['Pressure3pm'] - data['Pressure9am']\n",
    "\n",
    "sns.heatmap(data[['Pressure3pm','Pressure9am','DiffPressure', 'RainTomorrow']].corr(), annot=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After seeing the correlation matrix for pressure with our target.\n",
    "# We can say that the two variables affect it by almost the same way,\n",
    "# but we can't extract new better feature as temp.\n",
    "data.drop('DiffPressure',axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets analyze how the humidity affect the probability of raining tomorrow.\n",
    "# We have in our data 2 sources for temp (Humidity3pm, Humidity9am)\n",
    "# Lets show how these values affect our target.\n",
    "data['DiffHumidity'] = data['Humidity3pm'] - data['Humidity9am']\n",
    "\n",
    "sns.heatmap(data[['Humidity3pm','Humidity9am','DiffHumidity', 'RainTomorrow']].corr(), annot=True)\n",
    "\n",
    "# We can see that Humidity3pm is the most feature affect our target,\n",
    "# but the other two features affect also but with less effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see if Rainfall affect our target value or not.\n",
    "print(data[['Rainfall', 'RainTomorrow']].corr())\n",
    "sns.scatterplot(x=data.index, y=data['Rainfall'], hue=data['RainTomorrow'])\n",
    "\n",
    "# We can see that Rainfall affect our target slightly and we can notice that,\n",
    "# for large values of rain fall the probability to raintomorrow increases wrt not to rain. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see if RainToday affect our target value or not.\n",
    "data[['RainToday', 'RainTomorrow']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets analyze how the wind affect the probability of raining tomorrow.\n",
    "# We have in our data 3 sources for temp (WindSpeed9am, WindSpeed3pm, WindGustSpeed)\n",
    "# Lets show how these values affect our target.\n",
    "data[['WindGustSpeed',\t'WindSpeed9am',\t'WindSpeed3pm', 'RainTomorrow']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that only WindGustSpeed affect our target slightly.\n",
    "data.drop(['WindSpeed9am',\t'WindSpeed3pm'],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See counts of each WindDir9am category in dataset.\n",
    "plt.figure()\n",
    "plt.title(\"WindDir9am Counts\")\n",
    "sns.countplot(x='WindDir9am',data=data)\n",
    "plt.show()\n",
    "# We can see that WindDir9am has many outliers, but also it can diffrentiate between classes.\n",
    "plt.figure()\n",
    "plt.title(\"WindDir9am Effect on Price\")\n",
    "sns.boxplot(x=data['WindDir9am'], y=data['RainTomorrow'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See counts of each WindDir3pm category in dataset.\n",
    "plt.figure()\n",
    "plt.title(\"WindDir3pm Counts\")\n",
    "sns.countplot(x='WindDir3pm',data=data)\n",
    "plt.show()\n",
    "# We can see that WindDir3pm has many outliers, but also it can diffrentiate between classes.\n",
    "plt.figure()\n",
    "plt.title(\"WindDir3pm Effect on Price\")\n",
    "sns.boxplot(x=data['WindDir3pm'], y=data['RainTomorrow'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# See counts of each WindGustDir category in dataset.\n",
    "plt.figure()\n",
    "plt.title(\"WindGustDir Counts\")\n",
    "sns.countplot(x='WindGustDir',data=data)\n",
    "plt.show()\n",
    "# We can see that WindGustDir has many outliers, but also it can diffrentiate between classes.\n",
    "plt.figure()\n",
    "plt.title(\"WindGustDir Effect on Price\")\n",
    "sns.boxplot(x=data['WindGustDir'], y=data['RainTomorrow'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert WindDir9am into numerical attribute.\n",
    "data[\"WindDir9am\"] = data[\"WindDir9am\"].astype('category')\n",
    "data[\"WindDir9am\"] = data[\"WindDir9am\"].cat.codes\n",
    "\n",
    "# Convert WindDir3pm into numerical attribute.\n",
    "data[\"WindDir3pm\"] = data[\"WindDir3pm\"].astype('category')\n",
    "data[\"WindDir3pm\"] = data[\"WindDir3pm\"].cat.codes\n",
    "\n",
    "# Convert WindGustDir into numerical attribute.\n",
    "data[\"WindGustDir\"] = data[\"WindGustDir\"].astype('category')\n",
    "data[\"WindGustDir\"] = data[\"WindGustDir\"].cat.codes\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see how each attribute affect our target.\n",
    "\n",
    "sns.heatmap(data[['WindDir9am','WindDir3pm','WindGustDir', 'RainTomorrow']].corr(), annot=True)\n",
    "\n",
    "# We can see that Wind direction info is not very important, it doesn't affect our target significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winddir info has many outliers affect the model negativily\n",
    "data.drop(['WindDir9am','WindDir3pm','WindGustDir'],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fill the ramaining NA values in dataset by -100 value.\n",
    "data.fillna(-100,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training and Model building</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split independent and dependent variables\n",
    "x = data.drop('RainTomorrow',axis=1)\n",
    "y = data['RainTomorrow']\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest( k=3)\n",
    "selector.fit(X_train, y_train)\n",
    "X_train.columns[selector.get_support(indices=True)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Logistic regression grid params\n",
    "LM = LogisticRegression()\n",
    "\n",
    "# grid search for LM \n",
    "params_LM = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C'      : np.arange(1,5,0.5),\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "clf_LM  = GridSearchCV(LM,params_LM)\n",
    "\n",
    "clf_LM.fit(X_train, y_train)\n",
    "sorted(clf_LM.cv_results_.keys())\n",
    "print(clf_LM.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Logistic regression \n",
    "LM = LogisticRegression(C=1.0, penalty='l2', solver='newton-cg')\n",
    "LM.fit(X_train, y_train)\n",
    "accuracy = LM.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Random forest regression grid params\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# grid search for RF \n",
    "params_RF = {\n",
    "    'n_estimators': np.arange(100,1400,200),\n",
    "    'max_depth'   : np.arange(100,300,100),\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_leaf': np.arange(1,4,1)\n",
    "}\n",
    "clf_RF  = GridSearchCV(RF,params_RF)\n",
    "\n",
    "clf_RF.fit(X_train, y_train)\n",
    "sorted(clf_RF.cv_results_.keys())\n",
    "print(clf_RF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply RandomForest\n",
    "LM = RandomForestClassifier(max_depth= 100, max_features= 'log2', min_samples_leaf= 3, n_estimators= 1300)\n",
    "LM.fit(X_train, y_train)\n",
    "accuracy = LM.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Decision tree regression grid params\n",
    "DT = DecisionTreeClassifier()\n",
    "\n",
    "# grid search for DT\n",
    "params_DT = {\n",
    "    'max_depth'   : np.arange(100,1800,100),\n",
    "    'criterion'   : ['gini', 'entropy'],\n",
    "}\n",
    "clf_DT  = GridSearchCV(DT,params_DT)\n",
    "\n",
    "clf_DT.fit(X_train, y_train)\n",
    "sorted(clf_DT.cv_results_.keys())\n",
    "print(clf_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply DecisionTree\n",
    "LM = DecisionTreeClassifier(criterion ='entropy', max_depth= 1000)\n",
    "LM.fit(X_train, y_train)\n",
    "accuracy = LM.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply MLP regression grid params\n",
    "MLP = MLPClassifier()\n",
    "\n",
    "# grid search for MLP \n",
    "params_MLP = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation'        : ['tanh', 'relu'],\n",
    "    'solver'            : ['sgd', 'adam'],\n",
    "    'learning_rate'     : ['constant', 'adaptive'],\n",
    "    'alpha'             : [0.0001, 0.05],\n",
    "}\n",
    "clf_MLP  = GridSearchCV(MLP,params_MLP)\n",
    "\n",
    "clf_MLP.fit(X_train, y_train)\n",
    "sorted(clf_MLP.cv_results_.keys())\n",
    "print(clf_MLP.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply MLP\n",
    "LM = MLPClassifier(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (50, 100, 50), learning_rate= 'adaptive', solver= 'adam')\n",
    "LM.fit(X_train, y_train)\n",
    "accuracy = LM.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply SVM regression grid params\n",
    "SVM = SVC()\n",
    "\n",
    "# grid search for SVM \n",
    "params_SVM = {\n",
    "    'C'        : np.arange(1,3,1),\n",
    "    'kernel'   : ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "    'gamma'    : ['scale', 'auto'] \n",
    "}\n",
    "clf_SVM  = GridSearchCV(SVM,params_SVM)\n",
    "\n",
    "clf_SVM.fit(X_train, y_train)\n",
    "sorted(clf_SVM.cv_results_.keys())\n",
    "print(clf_SVM.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply SVM\n",
    "LM = SVC(C= 1, kernel= 'linear', gamma= 'scale', max_iter= 1600)\n",
    "LM.fit(X_train, y_train)\n",
    "accuracy = LM.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply KNN regression grid params\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "# grid search for LM \n",
    "params_KNN = {\n",
    "    'leaf_size'         : np.arange(30,100,10),\n",
    "    'metric'            : ['minkowski', 'precomputed'],\n",
    "    'n_neighbours'      : np.arange(5,15,1), \n",
    "    'p'                 : np.arange(1,5,1),\n",
    "    'weights'           : ['uniform', 'distance']\n",
    "}\n",
    "clf_KNN  = GridSearchCV(KNN,params_KNN)\n",
    "\n",
    "clf_KNN.fit(X_train, y_train)\n",
    "sorted(clf_KNN.cv_results_.keys())\n",
    "print(clf_KNN.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply KNN\n",
    "LM = KNeighborsClassifier(leaf_size= 40, metric= 'minkowski', n_neighbors= 10, p= 2, weights= 'uniform')\n",
    "LM.fit(X_train, y_train)\n",
    "accuracy = LM.score(X_test, y_test)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63ec835a8a230d72563f64f9e6bb1f5e26f5985585ff40cf0810c52b76825f48"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
